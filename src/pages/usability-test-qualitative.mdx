---
path: "/usability-test-qualitative"
title: "Qualitative Usability Tests"
---

import { Link } from "gatsby"

import uxMethods from "../data/ux-methods"
import MethodLayout from "../components/methods/layout-method"
import MethodSectionIntro from "../components/methods/section-intro"
import MethodSectionWhatIs from "../components/methods/section-whatis"
import MethodSectionNeeds from "../components/methods/section-needs"
import MethodSectionNeedsPartial from "../components/methods/section-needs-partials"
import MethodSectionSteps from "../components/methods/section-steps"
import MethodSectionTips from "../components/methods/section-tips"
import MethodSectionResources from "../components/methods/section-resources"

export const currentMethod = uxMethods.usability_test_qualitative

import SEO from "../components/seo"

<MethodLayout pageTitle={props.pageContext.frontmatter.title} method={currentMethod}>
  <SEO title={props.pageContext.frontmatter.title} />
  <MethodSectionIntro>
  <p>Before we talk about Qualitative Usability Tests, it’s important to understand what a Usability Test is in general.</p>
  <p>A Usability Test is a method used to evaluate how usable or intuitive your product is. This is done by observing and analysing representative users as they perform specific tasks in your product. Usability Tests allow you to identify any usability problems, collect qualitative and quantitative data, and determine your users’ satisfaction with your product or proposed designs early on in the design cycle.</p>
  <p>
    There are two types of Usability Tests: <strong>Quantitative Usability Tests</strong> and <strong>Qualitative Usability Tests</strong>. Quantitative Usability Testing is focused on collecting UX metrics (like time on task or task success) through controlled, specific tasks. A Qualitative Usability Test has more open-ended tasks and prioritizes observations, like identifying usability issues or user insights. 
  </p>
  </MethodSectionIntro>

<MethodSectionWhatIs
  method={currentMethod}
  title="What is a Qualitative Usability Test?"
>
  <p>
    A Qualitative Usability Test is a method that prioritizes observation when
    participants perform open-ended tasks  in a system as you collect feedback
    on usability issues or user insights.
  </p>
  <p>
    Qualitative Usability Tests are a type of Formative User Research, which
    basically means that the results from these tests inform how the design will
    evolve during the design process, however, they can also be performed on
    your existing product in order to inform the next round of design changes.
  </p>
  <p>
    Since the goal of this method is to guide you through the design process,
    Qualitative Usability Tests are effective with smaller sample sizes. This
    encourages quick feedback and quick iteration in order to reach your goals.
  </p>
  <p>
    Some cons of Qualitative Usability Tests are that they can be
    time-consuming, recruiting can be a challenge, and they can take a long time
    to analyse. Remote moderated testing can help make scheduling easier, and
    there are paid services out there to help with that, however, they can be
    quite expensive.
  </p>
</MethodSectionWhatIs>

<MethodSectionNeeds title="What do you need for a Qualitative Usability Test?">
  <MethodSectionNeedsPartial type="time">
    <ul>
      <li>A few days for scheduling participants and setting up the tasks</li>
      <li>15 minutes to 1 hour to conduct the test</li>
    </ul>
  </MethodSectionNeedsPartial>
  <MethodSectionNeedsPartial type="materials">
    <ul>
      <li>A prototype or existing product</li>
      <li>Recording equipment</li>
      <li>Something to take notes on</li>
    </ul>
  </MethodSectionNeedsPartial>
</MethodSectionNeeds>

<MethodSectionSteps
  method={currentMethod}
  title="How do you conduct a Qualitative Usability Test?"
>
  <ol>
    <li>
      <h3>Step 1: Decide what you want to test and why</h3>
      As mentioned above, Qualitative Usability Tests can be run on early designs,
      or your finished product. You just need to know what you want to test and why.
      For example, are you looking to evaluate certain areas of your existing product
      to uncover new potential features or fixes? Or are you looking to evaluate
      your early designs to see if you’re on track and to guide the next round of
      quick iterations?
    </li>
    <li>
      <h3>Step 2: Decide if you want moderated or unmoderated</h3>
      <p>
        Your next decision is to decide whether it will be moderated or
        unmoderated. A moderated test involves the active participation of a
        trained facilitator, while an unmoderated test is completed by test
        participants in their own environment without a facilitator present.
      </p>
      <p>
        Unmoderated tests are faster, and allow for greater sample sizes in a
        short amount of time, but there are several cons; you can’t ask follow
        ups, the data has higher variability, and there is a risk of “Cheater”
        participants (which are participants that are only in it for
        compensation and do not provide substantial feedback).
      </p>
    </li>
    <li>
      <h3>Step 3: Create your test plan and tasks</h3>
      <p>
        Next, you need to create your test script and tasks. Come up with as
        many tasks that you want feedback on and that will fit within your
        timeframe. Your tasks here should be open-ended and the flows your
        participants interact with should support the entire task and any
        possible edge cases.
      </p>
      <p>
        <strong>Some examples of qualitative tasks would be:</strong>
      </p>
      <ul>
        <li>
          Find a pair of runners that you like and pay for them using our site
        </li>
        <li>Find a way to get help on the site</li>
        <li>Use this dashboard to analyse your data</li>
      </ul>
    </li>
    <li>
      <h3>Step 4: Schedule and recruit participants</h3>
      <p>
        Once you know what you want to test, you will want to find participants.
        Ideally they are representative of your target audience and have the
        right amount of experience for the flows you are testing. For example,
        if you’re testing for feedback on a new sign-up flow, you may want
        participants that have never used your product before. If you’re testing
        an advanced feature, you may need participants with a lot of experience
        with your product.
      </p>
      <p>
        Qualitative Usability Tests are effective with small sample sizes
        (around 5 participants per round). The logic behind this is that after
        around 5 participants, you will start getting too much repetitive
        feedback, and it will no longer be worth your time and effort. Instead,
        you’re encouraged to make changes to your designs, then do another round
        of tests. Repeat this process until you feel you’ve reached your goal
        (or until you run out of time).
      </p>
      <p>
        This makes scheduling easy, since you only need 5 per round, but
        depending on how many rounds you do, scheduling could become difficult.
      </p>
    </li>
    <li>
      <h3>Step 5: Have them go through the tasks and note your observations</h3>
      Now you can have them go through the tasks while you record and document it.
      During the tasks, ask them to “think out loud”. Encouraging participants to
      talk through what they are looking for and why will unlock deeper insights
      into what they want, which will give you plenty of ideas on how to address
      it. If they start to get quiet, you can always ask “what are you thinking now?”.
    </li>
    <li>
      <h3>Step 6: Ask questions</h3>
      <p>
        In between each task, or once all tasks are complete, you can bring in
        some other research methods, like Quantitative Surveys and Qualitative
        Surveys, to get some additional feedback on the specific task or overall
        flow. You can even interview them with another set of questions, however
        this can only be done in moderated tests.
      </p>
      <p>
        When listening to their answers, it’s important to prioritize their
        actions in the tasks, rather than what they said in their responses. For
        example, they may tell you that they found the task easy, but in
        reality, they may have struggled for a long while at various points in
        the task.
      </p>
    </li>
    <li>
      <h3>Step 7: Analyse and report your findings</h3>
      <p>
        Pull out the main takeaways from each task then cross reference those
        takeaways with the results from the other participants. This will
        surface any patterns or trends in the feedback and possibly point to
        deeper insights. It will also allow you to make design proposals based
        off of user data, instead of just your opinions.
      </p>
      <p>
        Once you have this all in an easy-to-digest report, share your findings
        with your team and stakeholders. Make sure to include the main insights
        at the top, alongside any proposals you have on how to improve the
        designs before your next round of Usability Tests, or before you hand
        the designs over to the dev team.
      </p>
    </li>
  </ol>
</MethodSectionSteps>

<MethodSectionTips
  method={currentMethod}
  title="Tips for a great Qualitative Usability Test"
>
  <ul>
    <li>
      If they ask you questions or for help during the tasks, try to avoid
      answering them until the end of the test. You can simply say “I’m sorry,
      but I can’t answer that right now, as I would like to see what you would
      do if I wasn’t here to help you, but I would be more than happy to answer
      any questions you have at the end of the test.”
    </li>
    <li>
      Do a rehearsal Usability Test before you do it with an actual user. This
      will let you test all equipment, and to see how if your script or tasks
      need adjusting to better fit within your timeframe. For this rehearsal,
      you can use anyone from your company.
    </li>
    <li>
      You can still collect metrics (e.g. success/failure) in a Qualitative
      Usability Test, but that doesn’t make it a Quantitative Usability Test,
      typically because the sample size is too small and the tasks are too
      open-ended.
    </li>
    <li>
      Always remember that it’s more important to observe what they do, rather
      than what they say in response to your questions. Usability tests are
      about gathering observations over opinions, and what they say may
      drastically contradict what they actually did in the test.
    </li>
    <li>
      If you don’t have time to design for each possible edge case, you may need
      a generic “under construction” page to present to the user, then you can
      steer them back on track if they hit that screen. Just make sure to note
      anytime that it happened, and if you can, ask them questions on why they
      chose to go there.
    </li>
    <li>
      <p>
        Some good questions to encourage “thinking out loud” while they perform
        their tasks are:
      </p>
      <ul>
        <li>What are you thinking now?</li>
        <li>What are you trying to do?</li>
        <li>Why is that important to you?</li>
      </ul>
    </li>
    <li>
      When analysing the feedback, you should use your best judgement when
      deciding what to surface to your team. There may only be 1 participant
      that found a specific usability issue, but if it’s a big one that you feel
      should be addressed, you may want to include in your top takeaways.
    </li>
  </ul>
</MethodSectionTips>

<MethodSectionResources method={currentMethod} />

</MethodLayout>
